{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from datasetRegression import EEGDataset # Get the dataset class specific for regression models\n",
    "from torch.utils.data import random_split\n",
    "import neptune.new as neptune\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set\n",
      "../data/study_1A_mat_simple/S_01/night_1/artefact_annotations.npy\n",
      "../data/study_1A_mat_simple/S_01/night_1/EEG_raw_250hz.npy\n",
      "../data/study_1A_mat_simple/S_01/night_2/artefact_annotations.npy\n",
      "../data/study_1A_mat_simple/S_01/night_2/EEG_raw_250hz.npy\n",
      "../data/study_1A_mat_simple/S_01/night_3/artefact_annotations.npy\n",
      "../data/study_1A_mat_simple/S_01/night_3/EEG_raw_250hz.npy\n",
      "../data/study_1A_mat_simple/S_01/night_4/artefact_annotations.npy\n",
      "../data/study_1A_mat_simple/S_01/night_4/EEG_raw_250hz.npy\n",
      "../data/study_1A_mat_simple/S_02/night_1/artefact_annotations.npy\n",
      "../data/study_1A_mat_simple/S_02/night_1/EEG_raw_250hz.npy\n",
      "../data/study_1A_mat_simple/S_02/night_2/artefact_annotations.npy\n",
      "../data/study_1A_mat_simple/S_02/night_2/EEG_raw_250hz.npy\n",
      "../data/study_1A_mat_simple/S_02/night_3/artefact_annotations.npy\n",
      "../data/study_1A_mat_simple/S_02/night_3/EEG_raw_250hz.npy\n",
      "../data/study_1A_mat_simple/S_02/night_4/artefact_annotations.npy\n",
      "Lables for night 0 loaded\n",
      "../data/study_1A_mat_simple/S_02/night_4/EEG_raw_250hz.npy\n",
      "Night 0 data loaded\n",
      "../data/study_1A_mat_simple/S_03/night_1/artefact_annotations.npy\n",
      "Lables for night 1 loaded\n",
      "../data/study_1A_mat_simple/S_03/night_1/EEG_raw_250hz.npy\n",
      "Night 1 data loaded\n",
      "Training set\n",
      "../data/study_1A_mat_simple/S_01/night_1/artefact_annotations.npy\n",
      "Lables for night 0 loaded\n",
      "../data/study_1A_mat_simple/S_01/night_1/EEG_raw_250hz.npy\n",
      "Night 0 data loaded\n",
      "../data/study_1A_mat_simple/S_01/night_2/artefact_annotations.npy\n",
      "Lables for night 1 loaded\n",
      "../data/study_1A_mat_simple/S_01/night_2/EEG_raw_250hz.npy\n",
      "Night 1 data loaded\n",
      "../data/study_1A_mat_simple/S_01/night_3/artefact_annotations.npy\n",
      "Lables for night 2 loaded\n",
      "../data/study_1A_mat_simple/S_01/night_3/EEG_raw_250hz.npy\n",
      "Night 2 data loaded\n",
      "../data/study_1A_mat_simple/S_01/night_4/artefact_annotations.npy\n",
      "Lables for night 3 loaded\n",
      "../data/study_1A_mat_simple/S_01/night_4/EEG_raw_250hz.npy\n",
      "Night 3 data loaded\n",
      "../data/study_1A_mat_simple/S_02/night_1/artefact_annotations.npy\n",
      "Lables for night 4 loaded\n",
      "../data/study_1A_mat_simple/S_02/night_1/EEG_raw_250hz.npy\n",
      "Night 4 data loaded\n",
      "../data/study_1A_mat_simple/S_02/night_2/artefact_annotations.npy\n",
      "Lables for night 5 loaded\n",
      "../data/study_1A_mat_simple/S_02/night_2/EEG_raw_250hz.npy\n",
      "Night 5 data loaded\n",
      "../data/study_1A_mat_simple/S_02/night_3/artefact_annotations.npy\n",
      "Lables for night 6 loaded\n",
      "../data/study_1A_mat_simple/S_02/night_3/EEG_raw_250hz.npy\n",
      "Night 6 data loaded\n"
     ]
    }
   ],
   "source": [
    "# load in the dataset\n",
    "\n",
    "#raw_data_dir = '//uni.au.dk/dfs/Tech_EarEEG/Students/RD2022_Artefact_AkselStark/data/1A/study_1A_mat_simple'\n",
    "raw_data_dir = '../data'\n",
    "\n",
    "trainingNights = 7\n",
    "testNights = 2\n",
    "\n",
    "print(\"Test set\")\n",
    "ds2 = EEGDataset(raw_data_dir,testNights, 250, skips = trainingNights)\n",
    "\n",
    "print(\"Training set\")\n",
    "ds1 = EEGDataset(raw_data_dir,trainingNights, 250, skips = 0) #Instantiate a dataset using the directory of data, amount of night to include and amount of samples in a segment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' #Check for cuda \n",
    "print(f'Using {device} device')\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        #self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.BatchNorm1d(250),\n",
    "            nn.Linear(250, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid(), \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "model = NeuralNetwork()\n",
    "model.to(device)\n",
    "\n",
    "loss = nn.MSELoss() #L2 loss\n",
    "\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)# Reshape to 1 dimension if using binary classification, otherwise keep dimensions from model output\n",
    "        pred = pred.reshape(-1)\n",
    "        pred = pred.to(device)\n",
    "        yFloat = y.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        loss = loss_fn(pred, yFloat)\n",
    "        \n",
    "\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Neptune logging\n",
    "        run[\"training/batch/loss\"].log(loss)\n",
    "\n",
    "        if batch % 1000 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            print(\"Predicted values:\")\n",
    "            print(pred)\n",
    "            print(\"Actual values:\")\n",
    "            print(yFloat)\n",
    "\n",
    "\n",
    "\n",
    "def test_loop(dataloader_test, model, loss_fn, test_set = True):\n",
    "    size = len(dataloader_test.dataset)\n",
    "    num_batches = len(dataloader_test)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader_test:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X).reshape(-1).to(device) # Reshape to 1 dimension if using binary classification, otherwise keep dimensions from model output\n",
    "            test_loss += loss_fn(pred, y.type(torch.FloatTensor).to(device)).item()\n",
    "            #correct += (pred.round() == y).type(torch.float).sum().item()\n",
    "            \n",
    "\n",
    "    test_loss /= num_batches\n",
    "    #correct /= size\n",
    "    if test_set:\n",
    "        #print(f\"Test set Error: \\n Test Set Accuracy: {(100*correct):>0.5f}%, Avg Test Set loss: {test_loss:>8f} \\n\")\n",
    "        print(f\"Test set Error: \\n Avg Test Set loss: {test_loss:>8f} \\n\")\n",
    "        # Neptune logging\n",
    "        run[\"testing/batch/test_loss\"].log(test_loss)\n",
    "    else:\n",
    "        #print(f\"Training Set Error: \\n Training Set Accuracy: {(100*correct):>0.5f}%, Avg Training Set loss: {test_loss:>8f} \\n\")\n",
    "        print(f\"Training Set Error: \\n Avg Training Set loss: {test_loss:>8f} \\n\")\n",
    "        # Neptune logging\n",
    "        run[\"testing/batch/test_loss\"].log(test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test data (Commented out: Changed to loading different dataset class instances)\n",
    "#trainSamples = int(ds1.__len__()*0.7)\n",
    "#testSamples = int(ds1.__len__() - trainSamples)\n",
    "#training_data, test_data = random_split(ds1, (trainSamples,testSamples), generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "#train_dataloader = DataLoader(training_data, batch_size=64, drop_last = True) # Drop_last, to avoid incomplete batches, which won't work with weighted loss\n",
    "#test_dataloader = DataLoader(test_data, batch_size=64, drop_last = True) # Drop_last, to avoid incomplete batches, which won't work with weighted loss\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(ds1, batch_size=64, drop_last = True) # Drop_last, to avoid incomplete batches, which won't work with weighted loss\n",
    "test_dataloader = DataLoader(ds2, batch_size=64, drop_last = True) # Drop_last, to avoid incomplete batches, which won't work with weighted loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/aksel.s.madsen/artefact-detection/e/AR-15\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "# Initialize neptune\n",
    "run = neptune.init(\n",
    "    project=\"aksel.s.madsen/artefact-detection\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxYTA4NzcxMy1lYmQ2LTQ3NTctYjRhNC02Mzk1NjdjMWM0NmYifQ==\",\n",
    ")  # Credentials\n",
    "\n",
    "\n",
    "run['config/dataset/size'] = trainingNights # dict() object\n",
    "run['config/model'] = type(model).__name__\n",
    "run['config/modelSummary'] = summary(model, input_size=(batch_size, 250))\n",
    "run['config/optimizer'] = type(optimizer).__name__\n",
    "run['config/batch_size'] = batch_size\n",
    "run['config/test_night'] = testNights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.246790  [    0/4951495]\n",
      "Predicted values:\n",
      "tensor([0.5063, 0.5084, 0.5064, 0.5082, 0.5069, 0.5082, 0.5028, 0.5087, 0.5055,\n",
      "        0.5083, 0.5092, 0.5076, 0.5060, 0.5083, 0.5065, 0.5076, 0.5070, 0.5061,\n",
      "        0.5063, 0.5091, 0.5071, 0.5081, 0.5061, 0.5081, 0.5079, 0.5076, 0.5068,\n",
      "        0.5084, 0.5076, 0.5083, 0.5067, 0.5083, 0.5042, 0.5085, 0.5057, 0.5090,\n",
      "        0.5080, 0.5087, 0.5044, 0.5086, 0.5154, 0.5088, 0.4981, 0.5087, 0.5071,\n",
      "        0.5092, 0.5053, 0.5083, 0.5075, 0.5074, 0.5073, 0.5083, 0.5092, 0.5079,\n",
      "        0.5026, 0.5085, 0.5076, 0.5081, 0.5104, 0.5084, 0.5220, 0.5083, 0.5140,\n",
      "        0.5077], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values:\n",
      "tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        0.5600, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000], device='cuda:0')\n",
      "loss: 0.225399  [64000/4951495]\n",
      "Predicted values:\n",
      "tensor([0.5562, 0.4905, 0.4953, 0.4901, 0.5030, 0.4909, 0.4966, 0.4914, 0.4940,\n",
      "        0.4907, 0.4992, 0.4928, 0.5019, 0.4939, 0.5291, 0.4913, 0.5626, 0.4907,\n",
      "        0.4984, 0.4915, 0.5039, 0.4911, 0.5011, 0.4918, 0.5207, 0.4913, 0.4948,\n",
      "        0.4922, 0.7175, 0.4901, 0.4949, 0.4922, 0.5517, 0.4900, 0.5037, 0.4911,\n",
      "        0.4947, 0.4900, 0.5564, 0.4900, 0.8421, 0.4913, 0.4965, 0.4917, 0.6119,\n",
      "        0.4903, 0.8695, 0.4905, 0.5061, 0.4904, 0.5870, 0.4896, 0.4995, 0.4930,\n",
      "        0.6826, 0.4924, 0.5147, 0.4924, 0.5888, 0.4915, 0.5022, 0.4901, 0.4967,\n",
      "        0.4929], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values:\n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0.], device='cuda:0')\n",
      "loss: 0.252387  [128000/4951495]\n",
      "Predicted values:\n",
      "tensor([0.4827, 0.4682, 0.5141, 0.4679, 0.4904, 0.4684, 0.5834, 0.4797, 0.4981,\n",
      "        0.4762, 0.4811, 0.9913, 0.5050, 0.4893, 0.7425, 0.4834, 0.5227, 0.4722,\n",
      "        0.5178, 0.4823, 0.4706, 0.4705, 0.5018, 0.9755, 0.5076, 0.4858, 0.4708,\n",
      "        0.4740, 0.4742, 0.4991, 0.4811, 0.4701, 0.5170, 0.4695, 0.6743, 0.4695,\n",
      "        0.4902, 0.4769, 0.4843, 0.4692, 0.4808, 0.4690, 0.4833, 0.4693, 0.4813,\n",
      "        0.4699, 0.5213, 0.4690, 0.4758, 0.4684, 0.5760, 0.4689, 0.4821, 0.4687,\n",
      "        0.4727, 0.4682, 0.4860, 0.4686, 0.4737, 0.4681, 0.4756, 0.4684, 0.5788,\n",
      "        0.4678], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values:\n",
      "tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.7120,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000], device='cuda:0')\n",
      "loss: 0.173334  [192000/4951495]\n",
      "Predicted values:\n",
      "tensor([0.4760, 0.4063, 0.4542, 0.4063, 0.6379, 0.4063, 0.6859, 0.4063, 0.5437,\n",
      "        0.4063, 0.9868, 0.4063, 0.8872, 0.4063, 0.4179, 0.4063, 0.4063, 0.4063,\n",
      "        0.9457, 0.4063, 0.4390, 0.4063, 0.5450, 0.4063, 0.5801, 0.4063, 0.5920,\n",
      "        0.4063, 0.4530, 0.4063, 0.9415, 0.4063, 0.4854, 0.4063, 0.4628, 0.4063,\n",
      "        0.8795, 0.4063, 0.7467, 0.4063, 0.4422, 0.4063, 0.4776, 0.4063, 0.4572,\n",
      "        0.4063, 0.8899, 0.4063, 0.5162, 0.4063, 0.9050, 0.4063, 0.4476, 0.4063,\n",
      "        0.6016, 0.4063, 0.8058, 0.4063, 0.7483, 0.4063, 0.4592, 0.4063, 0.4485,\n",
      "        0.4063], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values:\n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0.], device='cuda:0')\n",
      "loss: 0.148763  [256000/4951495]\n",
      "Predicted values:\n",
      "tensor([0.4369, 0.3621, 0.8088, 0.3639, 0.4829, 0.3619, 0.4563, 0.3635, 0.4221,\n",
      "        0.3621, 0.4970, 0.3704, 0.9400, 0.3624, 0.9217, 0.3634, 0.4688, 0.3620,\n",
      "        0.7467, 0.3687, 0.3856, 0.3629, 0.4081, 0.3653, 0.4633, 0.3625, 0.9902,\n",
      "        0.3625, 0.3967, 0.3620, 0.4527, 0.3627, 0.6260, 0.3626, 0.4735, 0.3625,\n",
      "        0.9972, 0.3641, 0.4519, 0.3650, 0.5660, 0.3625, 0.9537, 0.3633, 0.9032,\n",
      "        0.3631, 0.5296, 0.3621, 0.9391, 0.3629, 0.4533, 0.3646, 0.9792, 0.3654,\n",
      "        0.4776, 0.3632, 0.4010, 0.3637, 0.6962, 0.3635, 0.4109, 0.3638, 0.4539,\n",
      "        0.3643], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values:\n",
      "tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 0.8600, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 0.6800, 0.0000, 0.9160, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 0.6680, 0.0000, 1.0000, 0.0000, 0.7200, 0.0000, 1.0000,\n",
      "        0.0000], device='cuda:0')\n",
      "loss: 0.144191  [320000/4951495]\n",
      "Predicted values:\n",
      "tensor([0.3786, 0.3051, 0.4363, 0.3051, 0.4432, 0.3051, 0.9969, 0.3051, 0.9744,\n",
      "        0.3051, 0.7679, 0.3051, 0.9865, 0.3051, 0.4005, 0.3051, 0.4925, 0.3051,\n",
      "        0.8293, 0.3051, 0.9747, 0.3051, 0.5125, 0.3051, 0.9245, 0.3051, 0.3943,\n",
      "        0.3051, 0.4895, 0.3051, 0.3051, 0.3051, 0.4039, 0.3051, 0.8944, 0.3051,\n",
      "        0.9765, 0.3051, 0.9444, 0.3051, 0.3895, 0.3051, 0.3885, 0.3051, 0.4154,\n",
      "        0.3051, 0.7961, 0.3051, 0.9980, 0.3051, 0.6337, 0.3051, 0.7161, 0.3051,\n",
      "        0.3880, 0.3051, 0.3617, 0.3051, 0.4012, 0.3051, 0.8757, 0.3051, 0.4431,\n",
      "        0.3051], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values:\n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0.], device='cuda:0')\n",
      "loss: 0.135519  [384000/4951495]\n",
      "Predicted values:\n",
      "tensor([0.4419, 0.2894, 0.7107, 0.2894, 0.3688, 0.2894, 0.6186, 0.2894, 0.9047,\n",
      "        0.2894, 0.3552, 0.2894, 0.4472, 0.2894, 0.4266, 0.2894, 0.4089, 0.2894,\n",
      "        0.9389, 0.2894, 0.4443, 0.2894, 0.5583, 0.2894, 0.7113, 0.2894, 0.3973,\n",
      "        0.2894, 0.9774, 0.2894, 1.0000, 0.2894, 0.2894, 0.2894, 0.9964, 0.2894,\n",
      "        0.4773, 0.2894, 0.4716, 0.2894, 0.9909, 0.2894, 0.7284, 0.2894, 0.3883,\n",
      "        0.2894, 0.4267, 0.2894, 0.9955, 0.2894, 0.7634, 0.2894, 0.3786, 0.2894,\n",
      "        0.9929, 0.2894, 0.3661, 0.2894, 0.3684, 0.2894, 0.5469, 0.2894, 0.5531,\n",
      "        0.2894], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values:\n",
      "tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.6800,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.8360, 0.0000,\n",
      "        1.0000, 0.0000, 0.6440, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000], device='cuda:0')\n",
      "loss: 0.162042  [448000/4951495]\n",
      "Predicted values:\n",
      "tensor([0.9951, 0.2006, 0.3130, 0.2020, 0.3393, 0.2008, 0.9674, 0.8866, 0.8828,\n",
      "        0.5401, 0.2365, 0.6114, 0.9996, 0.3510, 0.9026, 0.3589, 0.2570, 0.2860,\n",
      "        0.9969, 0.2261, 0.7005, 0.2063, 0.2330, 0.2000, 0.8899, 0.5136, 0.8941,\n",
      "        0.5008, 0.9999, 0.5231, 0.8683, 0.5333, 0.7508, 0.2032, 0.9655, 0.2029,\n",
      "        0.3917, 0.2021, 0.3537, 0.1987, 0.9874, 0.2996, 0.2857, 0.2049, 0.2644,\n",
      "        0.2074, 0.4610, 0.2300, 0.8303, 0.2177, 0.8064, 0.2029, 0.4469, 0.2006,\n",
      "        0.2781, 0.2041, 0.8343, 0.1987, 0.9121, 0.1985, 0.2486, 0.2005, 0.7459,\n",
      "        0.2010], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values:\n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.117759  [512000/4951495]\n",
      "Predicted values:\n",
      "tensor([0.4433, 0.2598, 0.9993, 0.2598, 0.4084, 0.2598, 0.8423, 0.2598, 0.9992,\n",
      "        0.2598, 0.8418, 0.2598, 0.5087, 0.2598, 0.4053, 0.2598, 0.4109, 0.2598,\n",
      "        0.3151, 0.2598, 0.5064, 0.2598, 0.3422, 0.2598, 0.9209, 0.2598, 0.8621,\n",
      "        0.2598, 0.7279, 0.2598, 0.5220, 0.2598, 0.4333, 0.2598, 0.9910, 0.2598,\n",
      "        0.3242, 0.2598, 0.8919, 0.2598, 0.7807, 0.2598, 0.4339, 0.2598, 0.9936,\n",
      "        0.2598, 0.9702, 0.2598, 0.4305, 0.2598, 0.4941, 0.2598, 1.0000, 0.2598,\n",
      "        0.5223, 0.2598, 0.2924, 0.2598, 0.9996, 0.2598, 0.4992, 0.2598, 0.3499,\n",
      "        0.2598], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values:\n",
      "tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 0.6640, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 0.6400, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        0.9400, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.7640,\n",
      "        0.0000], device='cuda:0')\n",
      "loss: 0.109388  [576000/4951495]\n",
      "Predicted values:\n",
      "tensor([0.9819, 0.2568, 0.9974, 0.2568, 0.8995, 0.2568, 0.4209, 0.2568, 0.3297,\n",
      "        0.2568, 0.4670, 0.2568, 0.8693, 0.2568, 0.6865, 0.2568, 0.5993, 0.2568,\n",
      "        0.4080, 0.2568, 0.5221, 0.2568, 0.4508, 0.2568, 0.4189, 0.2568, 0.4299,\n",
      "        0.2568, 0.4671, 0.2568, 0.4679, 0.2568, 0.9209, 0.2568, 0.3341, 0.2568,\n",
      "        0.4575, 0.2568, 0.9993, 0.2568, 0.5066, 0.2568, 0.8661, 0.2568, 0.8285,\n",
      "        0.2568, 0.4257, 0.2568, 1.0000, 0.2568, 0.5182, 0.2568, 0.5088, 0.2568,\n",
      "        0.9997, 0.2568, 0.9893, 0.2568, 0.9789, 0.2568, 0.9037, 0.2568, 0.4614,\n",
      "        0.2568], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values:\n",
      "tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.6640,\n",
      "        0.0000, 0.8960, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 0.6600, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000], device='cuda:0')\n",
      "loss: 0.114979  [640000/4951495]\n",
      "Predicted values:\n",
      "tensor([0.7486, 0.2212, 0.6991, 0.2216, 0.9808, 0.2292, 0.2677, 0.2183, 0.3243,\n",
      "        0.2188, 0.2978, 0.2188, 0.4088, 0.2250, 0.9998, 0.2374, 1.0000, 0.2315,\n",
      "        0.8509, 0.2181, 0.3428, 0.2184, 0.4320, 0.2184, 0.9126, 0.2181, 0.8791,\n",
      "        0.2234, 0.9459, 0.2188, 0.9997, 0.2180, 0.3052, 0.2195, 0.9730, 0.2265,\n",
      "        0.9913, 0.2180, 0.3633, 0.2227, 0.3937, 0.2296, 0.9434, 0.2183, 0.6002,\n",
      "        0.2180, 0.9985, 0.2246, 0.3713, 0.2256, 0.4974, 0.2224, 0.2338, 0.2189,\n",
      "        0.9985, 0.2233, 0.9844, 0.2201, 0.9999, 0.2213, 0.8449, 0.2192, 0.4412,\n",
      "        0.2176], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values:\n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0.], device='cuda:0')\n",
      "loss: 0.115717  [704000/4951495]\n",
      "Predicted values:\n",
      "tensor([0.5782, 0.2452, 0.4659, 0.2451, 0.8666, 0.3989, 0.4822, 0.2662, 0.9929,\n",
      "        0.2360, 0.3635, 0.2493, 0.4966, 0.2359, 0.7899, 0.2320, 0.9228, 0.2368,\n",
      "        0.4570, 0.2400, 0.9999, 0.2436, 0.3844, 0.2667, 0.4627, 0.2565, 0.9729,\n",
      "        0.2568, 0.9988, 0.2534, 0.3883, 0.2557, 0.4492, 0.2435, 0.6467, 0.2524,\n",
      "        0.4193, 0.2613, 1.0000, 0.2857, 0.6741, 0.4160, 0.3944, 0.3605, 0.7143,\n",
      "        0.2836, 0.8584, 0.2790, 0.6510, 0.2484, 0.9999, 0.2484, 0.9943, 0.2651,\n",
      "        0.9968, 0.3811, 0.5192, 0.2613, 0.4771, 0.2387, 1.0000, 0.2423, 0.3773,\n",
      "        0.2355], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values:\n",
      "tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.8760,\n",
      "        0.0000], device='cuda:0')\n",
      "loss: 0.098349  [768000/4951495]\n",
      "Predicted values:\n",
      "tensor([1.0000, 0.2081, 1.0000, 0.2081, 0.3526, 0.2081, 0.9902, 0.2081, 0.6486,\n",
      "        0.2081, 0.2081, 0.2081, 0.8093, 0.2081, 0.2714, 0.2081, 0.3335, 0.2081,\n",
      "        0.3739, 0.2081, 0.8697, 0.2081, 0.8304, 0.2081, 0.5009, 0.2081, 0.9999,\n",
      "        0.2081, 0.4506, 0.2081, 1.0000, 0.2081, 0.9453, 0.2081, 0.6178, 0.2081,\n",
      "        0.9084, 0.2081, 0.9997, 0.2081, 0.3752, 0.2081, 0.2994, 0.2081, 0.9681,\n",
      "        0.2081, 0.3489, 0.2081, 0.9455, 0.2081, 0.4981, 0.2081, 0.9848, 0.2081,\n",
      "        0.9013, 0.2081, 1.0000, 0.2081, 0.9522, 0.2081, 0.9455, 0.2081, 0.9346,\n",
      "        0.2081], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values:\n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0.], device='cuda:0')\n",
      "loss: 0.089610  [832000/4951495]\n",
      "Predicted values:\n",
      "tensor([0.1774, 0.1894, 0.6904, 0.1854, 0.6694, 0.1978, 0.9995, 0.1869, 0.6082,\n",
      "        0.1980, 0.9990, 0.2040, 0.2208, 0.1956, 0.9048, 0.1944, 0.4742, 0.2251,\n",
      "        0.7124, 0.1897, 0.9954, 0.2332, 0.1774, 0.1878, 0.4996, 0.2175, 1.0000,\n",
      "        0.1967, 0.5249, 0.1878, 0.1774, 0.2145, 0.9999, 0.1973, 0.9838, 0.1904,\n",
      "        1.0000, 0.1899, 0.9969, 0.2215, 0.4695, 0.1969, 0.9574, 0.2102, 1.0000,\n",
      "        0.1859, 0.9935, 0.1846, 0.3126, 0.2403, 0.9995, 0.1918, 0.9952, 0.1914,\n",
      "        0.5903, 0.1983, 0.9773, 0.1939, 0.4526, 0.1900, 0.9029, 0.1863, 0.7689,\n",
      "        0.2084], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values:\n",
      "tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.6920,\n",
      "        0.0000, 1.0000, 0.0000, 0.5080, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000], device='cuda:0')\n",
      "loss: 0.116898  [896000/4951495]\n",
      "Predicted values:\n",
      "tensor([0.6589, 0.3323, 0.9958, 0.2663, 0.4224, 0.2455, 0.2655, 0.2418, 0.4963,\n",
      "        0.2440, 0.9280, 0.2697, 0.9893, 0.2465, 0.7835, 0.2553, 0.4079, 0.2394,\n",
      "        0.4095, 0.2487, 1.0000, 0.2620, 0.9541, 0.2459, 0.4609, 0.2499, 0.3679,\n",
      "        0.2441, 0.5301, 0.2593, 0.9701, 0.2585, 0.3747, 0.2486, 0.9980, 0.2467,\n",
      "        0.3592, 0.2511, 0.3872, 0.2514, 0.4953, 0.2557, 0.4334, 0.2440, 0.2513,\n",
      "        0.2447, 0.9751, 0.2412, 1.0000, 0.2429, 1.0000, 0.2580, 0.8618, 0.2550,\n",
      "        0.2807, 0.2508, 1.0000, 0.2678, 0.9919, 0.3498, 0.9985, 0.2489, 0.5092,\n",
      "        0.4194], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values:\n",
      "tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.7120,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        0.6080, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.179576  [960000/4951495]\n",
      "Predicted values:\n",
      "tensor([0.5281, 0.3714, 0.4211, 0.3419, 0.4345, 0.3405, 0.4313, 0.3384, 0.8491,\n",
      "        0.3452, 0.9995, 0.3449, 0.8591, 0.3544, 0.8202, 0.3538, 0.5439, 0.3466,\n",
      "        0.5396, 0.3406, 0.7044, 0.3302, 0.4170, 0.3416, 0.8216, 0.3318, 0.4068,\n",
      "        0.3389, 0.5618, 0.3373, 1.0000, 0.3592, 0.4504, 0.3584, 0.4800, 1.0000,\n",
      "        0.8731, 0.3395, 0.5291, 0.3381, 0.9267, 0.3399, 0.7009, 0.3423, 0.3848,\n",
      "        0.3375, 0.4701, 0.3354, 0.5250, 0.3377, 0.8710, 0.3463, 0.8247, 0.4271,\n",
      "        0.4871, 1.0000, 0.9799, 0.4132, 0.3854, 0.3726, 0.3970, 0.3535, 0.5006,\n",
      "        0.3609], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values:\n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0.], device='cuda:0')\n",
      "loss: 0.085261  [1024000/4951495]\n",
      "Predicted values:\n",
      "tensor([0.4451, 0.2674, 0.9943, 0.2728, 1.0000, 0.2697, 0.9993, 0.2667, 0.3372,\n",
      "        0.2993, 0.9987, 0.2720, 0.9998, 0.2695, 1.0000, 0.2666, 0.8654, 0.2687,\n",
      "        1.0000, 0.2676, 0.9965, 0.2689, 0.9097, 0.2657, 0.8504, 0.2664, 0.7758,\n",
      "        0.2857, 0.8619, 0.2650, 0.6762, 0.2675, 0.8088, 0.2758, 0.5273, 0.2678,\n",
      "        0.4992, 0.2719, 0.9931, 0.2865, 0.9994, 0.2698, 1.0000, 0.2673, 0.4977,\n",
      "        0.2677, 1.0000, 0.2777, 0.5692, 0.2846, 0.8029, 0.2670, 0.6908, 0.2743,\n",
      "        0.5779, 0.2678, 0.2750, 0.2658, 0.4941, 0.2685, 0.9979, 0.2649, 0.4922,\n",
      "        0.2661], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values:\n",
      "tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        0.5000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000], device='cuda:0')\n",
      "loss: 0.105770  [1088000/4951495]\n",
      "Predicted values:\n",
      "tensor([1.0000, 0.2395, 0.8683, 0.2673, 0.7476, 0.2518, 0.9291, 0.2333, 0.9997,\n",
      "        0.2339, 0.4539, 0.2920, 0.9997, 0.2678, 0.2918, 0.2452, 0.9996, 0.2338,\n",
      "        0.5786, 0.2449, 0.2258, 0.2401, 0.2258, 0.2227, 0.8752, 0.2515, 0.7026,\n",
      "        0.2476, 0.3471, 0.2408, 0.4230, 0.2420, 0.5992, 0.2489, 1.0000, 0.2811,\n",
      "        0.6413, 0.2717, 0.6202, 0.2352, 0.3670, 0.2469, 0.9996, 0.2445, 1.0000,\n",
      "        0.2581, 0.9896, 0.2911, 0.2585, 0.2756, 0.6993, 0.2375, 0.9819, 0.2656,\n",
      "        0.4034, 0.2945, 1.0000, 0.2809, 0.5226, 0.2450, 0.9993, 0.2521, 0.5144,\n",
      "        0.2453], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values:\n",
      "tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 0.6800, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 0.9080, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.6880,\n",
      "        0.0000], device='cuda:0')\n",
      "loss: 0.126521  [1152000/4951495]\n",
      "Predicted values:\n",
      "tensor([0.5095, 0.2840, 0.9967, 0.2891, 1.0000, 0.2869, 0.9953, 0.2849, 0.6378,\n",
      "        0.2860, 1.0000, 0.2930, 0.2972, 0.2707, 0.6896, 0.2745, 0.4097, 0.3013,\n",
      "        0.4780, 0.2742, 0.9873, 0.2775, 0.5597, 0.2908, 0.8534, 0.2724, 0.9939,\n",
      "        0.2792, 0.9997, 0.2793, 0.5346, 0.3200, 0.9654, 0.2812, 0.9562, 0.2813,\n",
      "        0.4420, 0.2781, 0.6902, 0.3108, 0.7210, 0.2776, 0.9999, 0.2788, 0.9987,\n",
      "        0.2946, 0.6020, 0.2828, 0.4717, 0.2764, 0.9999, 0.3032, 0.6245, 0.9220,\n",
      "        0.4963, 0.4330, 0.4895, 0.9334, 0.9979, 0.3846, 0.8517, 0.3972, 0.5146,\n",
      "        0.2835], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values:\n",
      "tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 0.8600, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000], device='cuda:0')\n",
      "loss: 0.112166  [1216000/4951495]\n",
      "Predicted values:\n",
      "tensor([0.3269, 0.3347, 0.6805, 0.2805, 0.3642, 0.2415, 0.4805, 0.2023, 0.4038,\n",
      "        0.1864, 1.0000, 0.1854, 0.8425, 0.2141, 0.2827, 0.1896, 0.5653, 0.1859,\n",
      "        0.9993, 0.2161, 0.4129, 0.1918, 0.5869, 0.2622, 0.9946, 0.6494, 0.9954,\n",
      "        0.3700, 0.9915, 0.7324, 0.9991, 0.3485, 0.9999, 0.2530, 0.3630, 0.2457,\n",
      "        0.4694, 0.2135, 0.9950, 0.1969, 0.9571, 0.2288, 0.9714, 0.2357, 0.9975,\n",
      "        0.2130, 1.0000, 0.2064, 0.3292, 0.2030, 1.0000, 0.2642, 0.9990, 0.2612,\n",
      "        0.9580, 0.2133, 0.9995, 0.1835, 0.9972, 0.2437, 0.9970, 0.2120, 0.2495,\n",
      "        0.2286], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values:\n",
      "tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.4960, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.7120,\n",
      "        0.0000], device='cuda:0')\n",
      "loss: 0.071478  [1280000/4951495]\n",
      "Predicted values:\n",
      "tensor([0.4221, 0.1795, 0.5435, 0.1795, 1.0000, 0.1795, 0.9999, 0.1795, 0.4231,\n",
      "        0.1795, 1.0000, 0.1795, 0.9999, 0.1795, 0.6555, 0.1795, 0.9505, 0.1795,\n",
      "        1.0000, 0.1795, 0.7969, 0.1795, 0.7958, 0.1795, 0.9996, 0.1795, 0.9993,\n",
      "        0.1795, 0.6481, 0.1795, 0.4982, 0.1795, 0.8283, 0.1795, 0.9793, 0.1795,\n",
      "        0.9722, 0.1795, 1.0000, 0.1795, 1.0000, 0.1795, 0.5760, 0.1795, 0.4143,\n",
      "        0.1795, 1.0000, 0.1795, 0.3570, 0.1795, 1.0000, 0.1795, 0.3773, 0.1795,\n",
      "        0.9984, 0.1795, 0.6472, 0.1795, 0.4275, 0.1795, 0.6756, 0.1795, 0.4143,\n",
      "        0.1795], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values:\n",
      "tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.8480, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000], device='cuda:0')\n",
      "loss: 0.110615  [1344000/4951495]\n",
      "Predicted values:\n",
      "tensor([0.9981, 0.5575, 0.1389, 0.2511, 0.4756, 0.2055, 0.9895, 0.2655, 0.9881,\n",
      "        0.2564, 0.9790, 0.2107, 1.0000, 0.2486, 0.9998, 0.2572, 0.1916, 0.2024,\n",
      "        1.0000, 0.2023, 0.3760, 0.2275, 0.9739, 0.2150, 0.9078, 0.2251, 0.7335,\n",
      "        0.2588, 0.2770, 0.2089, 0.5528, 0.2437, 0.5389, 0.2119, 1.0000, 0.1915,\n",
      "        0.7406, 0.1886, 0.8330, 0.2363, 0.9959, 0.2293, 0.9891, 0.3684, 0.2587,\n",
      "        0.2348, 0.3083, 0.2278, 0.7495, 0.2151, 1.0000, 0.2214, 0.2266, 0.2385,\n",
      "        1.0000, 0.2449, 0.9996, 0.2572, 0.9183, 0.2241, 0.9991, 0.2095, 0.2084,\n",
      "        0.2360], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values:\n",
      "tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 0.5160, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.046897  [1408000/4951495]\n",
      "Predicted values:\n",
      "tensor([0.7030, 0.1489, 0.3972, 0.1489, 0.9937, 0.1489, 0.6683, 0.1489, 1.0000,\n",
      "        0.1489, 0.9454, 0.1489, 0.9983, 0.1489, 0.9998, 0.1489, 1.0000, 0.1489,\n",
      "        0.5555, 0.1489, 0.8879, 0.1489, 0.7286, 0.1489, 0.3577, 0.1489, 1.0000,\n",
      "        0.1489, 0.9999, 0.1489, 0.4877, 0.1489, 0.6621, 0.1489, 0.6985, 0.1489,\n",
      "        0.7866, 0.1489, 0.5435, 0.1489, 0.3910, 0.1489, 1.0000, 0.1489, 0.9926,\n",
      "        0.1489, 0.9040, 0.1489, 0.9998, 0.1489, 0.9948, 0.1489, 1.0000, 0.1489,\n",
      "        1.0000, 0.1489, 0.8621, 0.1489, 0.9676, 0.1489, 0.8604, 0.1489, 1.0000,\n",
      "        0.1489], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values:\n",
      "tensor([1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.9320, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 0.9560, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000,\n",
      "        1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000,\n",
      "        0.0000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    \n",
    "    train_loop(train_dataloader, model, loss, optimizer)    \n",
    "    test_loop(test_dataloader, model, loss)\n",
    "    #test_loop(train_dataloader, model, loss, test_set = False)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.stop() # Stop the neptune logging run"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d334debdbe0c15d06a22e1a5d8333410545070b029a2d558077d9bd2658c7aed"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
