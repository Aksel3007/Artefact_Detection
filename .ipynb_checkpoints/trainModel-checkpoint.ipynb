{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install neptune-client torch torchvision\n",
    "#!pip install simplejson\n",
    "#!pip install torchinfo\n",
    "#!pip install neptune-notebooks\n",
    "#!jupyter nbextension enable --py neptune-notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification dataset version: mar-30-1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import EEGDataset\n",
    "from torch.utils.data import random_split\n",
    "import neptune.new as neptune\n",
    "from torchinfo import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set\n",
      "../data/study_1A_mat_simple/S_01/night_1/artefact_annotations.npy\n",
      "../data/study_1A_mat_simple/S_01/night_1/EEG_raw_250hz.npy\n",
      "../data/study_1A_mat_simple/S_01/night_2/artefact_annotations.npy\n",
      "../data/study_1A_mat_simple/S_01/night_2/EEG_raw_250hz.npy\n",
      "../data/study_1A_mat_simple/S_01/night_3/artefact_annotations.npy\n",
      "../data/study_1A_mat_simple/S_01/night_3/EEG_raw_250hz.npy\n",
      "../data/study_1A_mat_simple/S_01/night_4/artefact_annotations.npy\n",
      "../data/study_1A_mat_simple/S_01/night_4/EEG_raw_250hz.npy\n",
      "../data/study_1A_mat_simple/S_02/night_1/artefact_annotations.npy\n",
      "../data/study_1A_mat_simple/S_02/night_1/EEG_raw_250hz.npy\n",
      "../data/study_1A_mat_simple/S_02/night_2/artefact_annotations.npy\n",
      "../data/study_1A_mat_simple/S_02/night_2/EEG_raw_250hz.npy\n",
      "../data/study_1A_mat_simple/S_02/night_3/artefact_annotations.npy\n",
      "../data/study_1A_mat_simple/S_02/night_3/EEG_raw_250hz.npy\n",
      "../data/study_1A_mat_simple/S_02/night_4/artefact_annotations.npy\n",
      "Lables for night 0 loaded\n",
      "../data/study_1A_mat_simple/S_02/night_4/EEG_raw_250hz.npy\n",
      "Night 0 data loaded\n",
      "../data/study_1A_mat_simple/S_03/night_1/artefact_annotations.npy\n",
      "Lables for night 1 loaded\n",
      "../data/study_1A_mat_simple/S_03/night_1/EEG_raw_250hz.npy\n",
      "Night 1 data loaded\n",
      "Training set\n",
      "../data/study_1A_mat_simple/S_01/night_1/artefact_annotations.npy\n",
      "Lables for night 0 loaded\n",
      "../data/study_1A_mat_simple/S_01/night_1/EEG_raw_250hz.npy\n",
      "Night 0 data loaded\n",
      "../data/study_1A_mat_simple/S_01/night_2/artefact_annotations.npy\n",
      "Lables for night 1 loaded\n",
      "../data/study_1A_mat_simple/S_01/night_2/EEG_raw_250hz.npy\n",
      "Night 1 data loaded\n",
      "../data/study_1A_mat_simple/S_01/night_3/artefact_annotations.npy\n",
      "Lables for night 2 loaded\n",
      "../data/study_1A_mat_simple/S_01/night_3/EEG_raw_250hz.npy\n",
      "Night 2 data loaded\n",
      "../data/study_1A_mat_simple/S_01/night_4/artefact_annotations.npy\n",
      "Lables for night 3 loaded\n",
      "../data/study_1A_mat_simple/S_01/night_4/EEG_raw_250hz.npy\n",
      "Night 3 data loaded\n",
      "../data/study_1A_mat_simple/S_02/night_1/artefact_annotations.npy\n",
      "Lables for night 4 loaded\n",
      "../data/study_1A_mat_simple/S_02/night_1/EEG_raw_250hz.npy\n",
      "Night 4 data loaded\n",
      "../data/study_1A_mat_simple/S_02/night_2/artefact_annotations.npy\n",
      "Lables for night 5 loaded\n",
      "../data/study_1A_mat_simple/S_02/night_2/EEG_raw_250hz.npy\n",
      "Night 5 data loaded\n",
      "../data/study_1A_mat_simple/S_02/night_3/artefact_annotations.npy\n",
      "Lables for night 6 loaded\n",
      "../data/study_1A_mat_simple/S_02/night_3/EEG_raw_250hz.npy\n",
      "Night 6 data loaded\n"
     ]
    }
   ],
   "source": [
    "# load in the dataset\n",
    "\n",
    "#raw_data_dir = '//uni.au.dk/dfs/Tech_EarEEG/Students/RD2022_Artefact_AkselStark/data/1A/study_1A_mat_simple'\n",
    "raw_data_dir = '../data'\n",
    "\n",
    "trainingNights = 7\n",
    "testNights = 2\n",
    "segLength = 750\n",
    "\n",
    "print(\"Test set\")\n",
    "ds2 = EEGDataset(raw_data_dir,testNights, segLength, skips = trainingNights)\n",
    "\n",
    "print(\"Training set\")\n",
    "ds1 = EEGDataset(raw_data_dir,trainingNights, segLength, skips = 0) #Instantiate a dataset using the directory of data, amount of night to include and amount of samples in a segment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_ratio:0.9875976387812295\n"
     ]
    }
   ],
   "source": [
    "#Calculate class imbalance\n",
    "balancing_dataloader = DataLoader(ds1, drop_last = True) # Drop_last, to avoid incomplete batches, which won't work with weighted loss\n",
    "artefacts = 0\n",
    "good_samples = 0\n",
    "for batch, (X, y) in enumerate(balancing_dataloader):\n",
    "    if y == 1:\n",
    "        artefacts += 1\n",
    "    else:\n",
    "        good_samples += 1\n",
    "    if batch > 100000:\n",
    "        break\n",
    "\n",
    "class_ratio = good_samples/artefacts\n",
    "print(f\"class_ratio:{class_ratio}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' #Check for cuda \n",
    "print(f'Using {device} device')\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        #self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.BatchNorm1d(segLength+2),\n",
    "            nn.Linear(segLength+2, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid(), \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "model = NeuralNetwork()\n",
    "model.to(device)\n",
    "\n",
    "#pos_weight: amount of positive examples compared to negative examples. Calculate as: negative_examples/positive_examples\n",
    "loss = nn.BCEWithLogitsLoss(pos_weight = class_ratio*torch.ones([batch_size]).to(device)) \n",
    "\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)# Reshape to 1 dimension if using binary classification, otherwise keep dimensions from model output\n",
    "        pred = pred.reshape(-1)\n",
    "        pred = pred.to(device)\n",
    "        yFloat = y.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "        loss = loss_fn(pred, yFloat)\n",
    "        \n",
    "\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Neptune logging\n",
    "        run[\"training/batch/loss\"].log(loss)\n",
    "        \n",
    "\n",
    "        if batch % 1000 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "        \n",
    "        if batch % 10000 == 0:\n",
    "            print(f\"Predicted values: \\n{pred}\")\n",
    "            print(f\"Actual values: \\n{yFloat}\")\n",
    "            print(f\"Difference: \\n{(yFloat-pred)}\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader_test, model, loss_fn, test_set = True):\n",
    "    size = len(dataloader_test.dataset)\n",
    "    num_batches = len(dataloader_test)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader_test:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X).reshape(-1).to(device) # Reshape to 1 dimension if using binary classification, otherwise keep dimensions from model output\n",
    "            test_loss += loss_fn(pred, y.type(torch.FloatTensor).to(device)).item()\n",
    "            correct += (pred.round() == y).type(torch.float).sum().item()\n",
    "            \n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    \n",
    "    \n",
    "    \n",
    "    if test_set:\n",
    "        print(f\"Test set Error: \\n Test Set Accuracy: {(100*correct):>0.5f}%, Avg Test Set loss: {test_loss:>8f} \\n\")\n",
    "        \n",
    "        # Neptune logging\n",
    "        run[\"testing/batch/test_loss\"].log(test_loss)\n",
    "        run[\"testing/batch/test_Acc\"].log(100*correct)\n",
    "    \n",
    "    else:\n",
    "        print(f\"Training Set Error: \\n Training Set Accuracy: {(100*correct):>0.5f}%, Avg Training Set loss: {test_loss:>8f} \\n\")\n",
    "        \n",
    "        # Neptune logging\n",
    "        run[\"testing/batch/training_loss\"].log(test_loss)\n",
    "        run[\"testing/batch/training_Acc\"].log(100*correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test data (Commented out: Changed to loading different dataset class instances)\n",
    "#trainSamples = int(ds1.__len__()*0.7)\n",
    "#testSamples = int(ds1.__len__() - trainSamples)\n",
    "#training_data, test_data = random_split(ds1, (trainSamples,testSamples), generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "#train_dataloader = DataLoader(training_data, batch_size=64, drop_last = True) # Drop_last, to avoid incomplete batches, which won't work with weighted loss\n",
    "#test_dataloader = DataLoader(test_data, batch_size=64, drop_last = True) # Drop_last, to avoid incomplete batches, which won't work with weighted loss\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(ds1, batch_size=64, drop_last = True) # Drop_last, to avoid incomplete batches, which won't work with weighted loss\n",
    "test_dataloader = DataLoader(ds2, batch_size=64, drop_last = True) # Drop_last, to avoid incomplete batches, which won't work with weighted loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/aksel.s.madsen/artefact-detection/e/AR-37\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "# Initialize neptune\n",
    "run = neptune.init(\n",
    "    project=\"aksel.s.madsen/artefact-detection\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxYTA4NzcxMy1lYmQ2LTQ3NTctYjRhNC02Mzk1NjdjMWM0NmYifQ==\",\n",
    "    source_files=[\"trainModel.ipynb\", \"dataset.py\"]\n",
    ")  # Credentials\n",
    "\n",
    "\n",
    "run['config/dataset/size'] = trainingNights # dict() object\n",
    "run['config/model'] = type(model).__name__\n",
    "run['config/modelSummary'] = summary(model, input_size=(batch_size, segLength + 2))\n",
    "run['config/optimizer'] = type(optimizer).__name__\n",
    "run['config/batch_size'] = batch_size\n",
    "run['config/test_night'] = testNights\n",
    "run['config/learning_rate'] = learning_rate\n",
    "run['config/segLength'] = segLength\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.666107  [    0/1650495]\n",
      "Predicted values: \n",
      "tensor([0.4896, 0.4903, 0.4902, 0.4902, 0.4828, 0.4904, 0.4907, 0.4904, 0.4923,\n",
      "        0.4902, 0.4740, 0.4905, 0.4817, 0.4906, 0.4901, 0.4912, 0.4963, 0.4923,\n",
      "        0.4967, 0.4921, 0.4894, 0.4902, 0.4919, 0.4902, 0.4882, 0.4903, 0.4915,\n",
      "        0.4901, 0.4921, 0.4910, 0.4921, 0.4909, 0.4916, 0.4905, 0.4641, 0.4908,\n",
      "        0.4928, 0.4908, 0.4895, 0.4898, 0.4869, 0.4907, 0.4914, 0.4952, 0.4578,\n",
      "        0.4927, 0.4938, 0.4903, 0.4913, 0.4915, 0.4879, 0.4909, 0.4902, 0.4918,\n",
      "        0.4844, 0.4899, 0.4905, 0.4904, 0.4930, 0.4899, 0.4891, 0.4898, 0.4906,\n",
      "        0.4907], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values: \n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 1., 1., 1., 0., 1., 0.], device='cuda:0')\n",
      "Difference: \n",
      "tensor([ 0.5104, -0.4903,  0.5098, -0.4902,  0.5172, -0.4904,  0.5093, -0.4904,\n",
      "         0.5077, -0.4902,  0.5260, -0.4905,  0.5183, -0.4906,  0.5099, -0.4912,\n",
      "         0.5037, -0.4923,  0.5033, -0.4921,  0.5106, -0.4902,  0.5081, -0.4902,\n",
      "         0.5118, -0.4903,  0.5085, -0.4901,  0.5079, -0.4910,  0.5079, -0.4909,\n",
      "         0.5084, -0.4905,  0.5359, -0.4908,  0.5072,  0.5092,  0.5105, -0.4898,\n",
      "         0.5131, -0.4907,  0.5086,  0.5048,  0.5422,  0.5073,  0.5062, -0.4903,\n",
      "         0.5087,  0.5085,  0.5121,  0.5091,  0.5098,  0.5082,  0.5156, -0.4899,\n",
      "         0.5095, -0.4904,  0.5070,  0.5101,  0.5109, -0.4898,  0.5094, -0.4907],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss: 0.615926  [64000/1650495]\n",
      "loss: 0.538297  [128000/1650495]\n",
      "loss: 0.550636  [192000/1650495]\n",
      "loss: 0.553214  [256000/1650495]\n",
      "loss: 0.512660  [320000/1650495]\n",
      "loss: 0.811003  [384000/1650495]\n",
      "loss: 0.557822  [448000/1650495]\n",
      "loss: 0.609329  [512000/1650495]\n",
      "loss: 0.513869  [576000/1650495]\n",
      "loss: 0.811346  [640000/1650495]\n",
      "Predicted values: \n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9937, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values: \n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0.], device='cuda:0')\n",
      "Difference: \n",
      "tensor([ 0.0000e+00, -1.0000e+00,  0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
      "        -1.0000e+00,  0.0000e+00, -1.0000e+00,  0.0000e+00, -1.0000e+00,\n",
      "         0.0000e+00, -1.0000e+00,  0.0000e+00, -1.0000e+00,  1.5020e-05,\n",
      "        -1.0000e+00,  0.0000e+00, -1.0000e+00,  0.0000e+00, -1.0000e+00,\n",
      "         3.1233e-05, -1.0000e+00,  0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
      "        -1.0000e+00,  0.0000e+00, -1.0000e+00,  0.0000e+00, -1.0000e+00,\n",
      "         0.0000e+00, -1.0000e+00,  0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
      "        -1.0000e+00,  6.3228e-03, -1.0000e+00,  0.0000e+00, -1.0000e+00,\n",
      "         0.0000e+00, -1.0000e+00,  0.0000e+00, -1.0000e+00,  0.0000e+00,\n",
      "        -1.0000e+00,  0.0000e+00, -1.0000e+00,  1.5497e-06, -1.0000e+00,\n",
      "         0.0000e+00, -1.0000e+00,  0.0000e+00, -1.0000e+00,  1.0371e-05,\n",
      "        -1.0000e+00,  0.0000e+00, -1.0000e+00,  0.0000e+00, -1.0000e+00,\n",
      "         1.1921e-07, -1.0000e+00,  1.9073e-06, -1.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "loss: 0.811312  [704000/1650495]\n",
      "loss: 0.501811  [768000/1650495]\n",
      "loss: 0.517359  [832000/1650495]\n",
      "loss: 0.549775  [896000/1650495]\n",
      "loss: 0.510361  [960000/1650495]\n",
      "loss: 0.517806  [1024000/1650495]\n",
      "loss: 0.535632  [1088000/1650495]\n",
      "loss: 0.506973  [1152000/1650495]\n",
      "loss: 0.547890  [1216000/1650495]\n",
      "loss: 0.511053  [1280000/1650495]\n",
      "Predicted values: \n",
      "tensor([1.0000e+00, 8.9523e-06, 2.6783e-01, 7.9989e-06, 1.0000e+00, 1.0816e-05,\n",
      "        1.0000e+00, 1.1840e-05, 1.0000e+00, 7.6802e-06, 1.0000e+00, 1.1985e-05,\n",
      "        1.0000e+00, 3.2178e-05, 1.0000e+00, 1.6208e-05, 1.0000e+00, 1.0198e-05,\n",
      "        1.0000e+00, 9.9652e-06, 1.0000e+00, 1.3979e-05, 1.0000e+00, 2.5685e-05,\n",
      "        1.0000e+00, 1.0020e-05, 1.0000e+00, 1.7172e-05, 1.0000e+00, 9.5695e-06,\n",
      "        1.0000e+00, 9.1237e-06, 1.0000e+00, 1.0744e-05, 9.9660e-01, 1.2596e-05,\n",
      "        2.9630e-03, 1.1572e-05, 1.0000e+00, 8.8145e-06, 1.0000e+00, 3.2737e-05,\n",
      "        1.0000e+00, 9.4457e-06, 1.0000e+00, 3.6957e-05, 1.0000e+00, 1.0535e-05,\n",
      "        1.0000e+00, 1.1114e-05, 1.0000e+00, 1.3022e-05, 9.9991e-01, 1.4922e-05,\n",
      "        1.0000e+00, 1.4326e-05, 1.0000e+00, 1.1183e-05, 1.0000e+00, 2.6156e-05,\n",
      "        1.0000e+00, 2.1818e-05, 1.0000e+00, 3.3174e-05], device='cuda:0',\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values: \n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0.], device='cuda:0')\n",
      "Difference: \n",
      "tensor([ 0.0000e+00, -8.9523e-06,  7.3217e-01, -7.9989e-06,  0.0000e+00,\n",
      "        -1.0816e-05,  0.0000e+00, -1.1840e-05,  0.0000e+00, -7.6802e-06,\n",
      "         0.0000e+00, -1.1985e-05,  0.0000e+00, -3.2178e-05,  0.0000e+00,\n",
      "        -1.6208e-05,  0.0000e+00, -1.0198e-05,  0.0000e+00, -9.9652e-06,\n",
      "         0.0000e+00, -1.3979e-05,  0.0000e+00, -2.5685e-05,  0.0000e+00,\n",
      "        -1.0020e-05,  0.0000e+00, -1.7172e-05,  0.0000e+00, -9.5695e-06,\n",
      "         4.7684e-07, -9.1237e-06,  0.0000e+00, -1.0744e-05,  3.4024e-03,\n",
      "        -1.2596e-05,  9.9704e-01, -1.1572e-05,  0.0000e+00, -8.8145e-06,\n",
      "         0.0000e+00, -3.2737e-05,  0.0000e+00, -9.4457e-06,  0.0000e+00,\n",
      "        -3.6957e-05,  0.0000e+00, -1.0535e-05,  0.0000e+00, -1.1114e-05,\n",
      "         0.0000e+00, -1.3022e-05,  8.5950e-05, -1.4922e-05,  0.0000e+00,\n",
      "        -1.4326e-05,  8.3447e-07, -1.1183e-05,  0.0000e+00, -2.6156e-05,\n",
      "         0.0000e+00, -2.1818e-05,  0.0000e+00, -3.3174e-05], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "loss: 0.514987  [1344000/1650495]\n",
      "loss: 0.501306  [1408000/1650495]\n",
      "loss: 0.507262  [1472000/1650495]\n",
      "loss: 0.845628  [1536000/1650495]\n",
      "loss: 0.501350  [1600000/1650495]\n",
      "Test set Error: \n",
      " Test Set Accuracy: 84.89080%, Avg Test Set loss: 0.567371 \n",
      "\n",
      "Training Set Error: \n",
      " Training Set Accuracy: 91.74593%, Avg Training Set loss: 0.535605 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.529170  [    0/1650495]\n",
      "Predicted values: \n",
      "tensor([1.0000e+00, 3.5044e-05, 1.0000e+00, 1.2357e-04, 1.3414e-01, 1.2029e-04,\n",
      "        2.8512e-01, 4.4889e-05, 1.0000e+00, 3.6317e-05, 1.0000e+00, 2.5782e-05,\n",
      "        1.1520e-03, 2.6881e-05, 9.8381e-01, 2.9430e-05, 1.0000e+00, 6.8962e-05,\n",
      "        1.0000e+00, 7.2020e-05, 1.0000e+00, 2.7475e-05, 1.0000e+00, 4.1906e-05,\n",
      "        1.0000e+00, 3.8908e-05, 9.9279e-01, 1.9828e-05, 5.3531e-02, 3.9850e-05,\n",
      "        1.3908e-03, 4.6927e-05, 9.6486e-01, 5.6076e-05, 9.9971e-01, 5.7604e-05,\n",
      "        1.0000e+00, 9.5590e-05, 1.0000e+00, 1.0285e-03, 1.0000e+00, 5.0651e-05,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0106e-04,\n",
      "        1.0540e-04, 1.0572e-04, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.4319e-03,\n",
      "        3.4054e-01, 3.2212e-05, 1.0000e+00, 3.6072e-05, 1.7639e-03, 4.4699e-05,\n",
      "        1.0000e+00, 3.4794e-05, 9.0749e-02, 2.6237e-05], device='cuda:0',\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values: \n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 1., 1., 1., 0., 1., 0.], device='cuda:0')\n",
      "Difference: \n",
      "tensor([ 0.0000e+00, -3.5044e-05,  1.9073e-06, -1.2357e-04,  8.6586e-01,\n",
      "        -1.2029e-04,  7.1488e-01, -4.4889e-05,  0.0000e+00, -3.6317e-05,\n",
      "         0.0000e+00, -2.5782e-05,  9.9885e-01, -2.6881e-05,  1.6190e-02,\n",
      "        -2.9430e-05,  0.0000e+00, -6.8962e-05,  0.0000e+00, -7.2020e-05,\n",
      "         0.0000e+00, -2.7475e-05,  0.0000e+00, -4.1906e-05,  0.0000e+00,\n",
      "        -3.8908e-05,  7.2093e-03, -1.9828e-05,  9.4647e-01, -3.9850e-05,\n",
      "         9.9861e-01, -4.6927e-05,  3.5136e-02, -5.6076e-05,  2.8855e-04,\n",
      "        -5.7604e-05,  0.0000e+00,  9.9990e-01,  0.0000e+00, -1.0285e-03,\n",
      "         0.0000e+00, -5.0651e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         8.3447e-07,  0.0000e+00, -1.0106e-04,  9.9989e-01,  9.9989e-01,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  9.9857e-01,  6.5946e-01,\n",
      "        -3.2212e-05,  1.1921e-07, -3.6072e-05,  9.9824e-01,  9.9996e-01,\n",
      "         0.0000e+00, -3.4794e-05,  9.0925e-01, -2.6237e-05], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.595177  [64000/1650495]\n",
      "loss: 0.502264  [128000/1650495]\n",
      "loss: 0.519503  [192000/1650495]\n",
      "loss: 0.507177  [256000/1650495]\n",
      "loss: 0.511677  [320000/1650495]\n",
      "loss: 0.505144  [384000/1650495]\n",
      "loss: 0.561956  [448000/1650495]\n",
      "loss: 0.543433  [512000/1650495]\n",
      "loss: 0.513977  [576000/1650495]\n",
      "loss: 0.812391  [640000/1650495]\n",
      "Predicted values: \n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.9942, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.9998, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.7674, 1.0000, 1.0000,\n",
      "        1.0000], device='cuda:0', grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values: \n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0.], device='cuda:0')\n",
      "Difference: \n",
      "tensor([ 0.0000, -1.0000,  0.0000, -1.0000,  0.0000, -1.0000,  0.0000, -1.0000,\n",
      "         0.0000, -1.0000,  0.0000, -1.0000,  0.0000, -1.0000,  0.0000, -1.0000,\n",
      "         0.0000, -1.0000,  0.0058, -1.0000,  0.0000, -1.0000,  0.0000, -1.0000,\n",
      "         0.0000, -1.0000,  0.0000, -1.0000,  0.0000, -1.0000,  0.0000, -1.0000,\n",
      "         0.0000, -1.0000,  0.0000, -1.0000,  0.0000, -1.0000,  0.0000, -1.0000,\n",
      "         0.0000, -1.0000,  0.0000, -1.0000,  0.0000, -1.0000,  0.0000, -0.9998,\n",
      "         0.0000, -1.0000,  0.0000, -1.0000,  0.0000, -1.0000,  0.0000, -1.0000,\n",
      "         0.0000, -1.0000,  0.0000, -1.0000,  0.2326, -1.0000,  0.0000, -1.0000],\n",
      "       device='cuda:0', grad_fn=<SubBackward0>)\n",
      "loss: 0.516213  [704000/1650495]\n",
      "loss: 0.501269  [768000/1650495]\n",
      "loss: 0.512395  [832000/1650495]\n",
      "loss: 0.538636  [896000/1650495]\n",
      "loss: 0.501785  [960000/1650495]\n",
      "loss: 0.522306  [1024000/1650495]\n",
      "loss: 0.517846  [1088000/1650495]\n",
      "loss: 0.502139  [1152000/1650495]\n",
      "loss: 0.530370  [1216000/1650495]\n",
      "loss: 0.507114  [1280000/1650495]\n",
      "Predicted values: \n",
      "tensor([1.0000e+00, 7.4492e-06, 1.0000e+00, 6.5628e-06, 1.0000e+00, 8.8883e-06,\n",
      "        1.0000e+00, 9.9884e-06, 1.0000e+00, 6.5122e-06, 9.9997e-01, 1.1734e-05,\n",
      "        1.0000e+00, 2.3876e-05, 1.0000e+00, 1.4389e-05, 1.0000e+00, 9.3059e-06,\n",
      "        1.0000e+00, 8.3414e-06, 1.0000e+00, 1.1842e-05, 1.0000e+00, 2.8560e-05,\n",
      "        1.0000e+00, 8.7367e-06, 1.0000e+00, 1.5842e-05, 1.0000e+00, 8.1592e-06,\n",
      "        1.0000e+00, 8.6942e-06, 1.7569e-03, 9.5850e-06, 1.0000e+00, 1.1398e-05,\n",
      "        1.0000e+00, 9.9074e-06, 1.0000e+00, 7.3645e-06, 1.0000e+00, 3.0740e-05,\n",
      "        1.0000e+00, 7.5894e-06, 1.0000e+00, 3.0789e-05, 1.0000e+00, 8.1340e-06,\n",
      "        1.0000e+00, 1.0405e-05, 1.0000e+00, 1.1368e-05, 1.0000e+00, 1.1855e-05,\n",
      "        9.9996e-01, 1.0531e-05, 1.0000e+00, 9.7438e-06, 1.0000e+00, 2.5085e-05,\n",
      "        1.0000e+00, 2.1264e-05, 1.0000e+00, 3.9285e-05], device='cuda:0',\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values: \n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0.], device='cuda:0')\n",
      "Difference: \n",
      "tensor([ 0.0000e+00, -7.4492e-06,  0.0000e+00, -6.5628e-06,  0.0000e+00,\n",
      "        -8.8883e-06,  0.0000e+00, -9.9884e-06,  0.0000e+00, -6.5122e-06,\n",
      "         3.2544e-05, -1.1734e-05,  0.0000e+00, -2.3876e-05,  0.0000e+00,\n",
      "        -1.4389e-05,  0.0000e+00, -9.3059e-06,  0.0000e+00, -8.3414e-06,\n",
      "         0.0000e+00, -1.1842e-05,  0.0000e+00, -2.8560e-05,  0.0000e+00,\n",
      "        -8.7367e-06,  0.0000e+00, -1.5842e-05,  0.0000e+00, -8.1592e-06,\n",
      "         0.0000e+00, -8.6942e-06,  9.9824e-01, -9.5850e-06,  0.0000e+00,\n",
      "        -1.1398e-05,  0.0000e+00, -9.9074e-06,  0.0000e+00, -7.3645e-06,\n",
      "         0.0000e+00, -3.0740e-05,  0.0000e+00, -7.5894e-06,  0.0000e+00,\n",
      "        -3.0789e-05,  0.0000e+00, -8.1340e-06,  0.0000e+00, -1.0405e-05,\n",
      "         0.0000e+00, -1.1368e-05,  0.0000e+00, -1.1855e-05,  3.8147e-05,\n",
      "        -1.0531e-05,  1.1921e-07, -9.7438e-06,  9.5367e-07, -2.5085e-05,\n",
      "         0.0000e+00, -2.1264e-05,  0.0000e+00, -3.9285e-05], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "loss: 0.505102  [1344000/1650495]\n",
      "loss: 0.532890  [1408000/1650495]\n",
      "loss: 0.509794  [1472000/1650495]\n",
      "loss: 0.826486  [1536000/1650495]\n",
      "loss: 0.506007  [1600000/1650495]\n",
      "Test set Error: \n",
      " Test Set Accuracy: 85.85882%, Avg Test Set loss: 0.560397 \n",
      "\n",
      "Training Set Error: \n",
      " Training Set Accuracy: 92.23300%, Avg Training Set loss: 0.533366 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.502267  [    0/1650495]\n",
      "Predicted values: \n",
      "tensor([1.0000e+00, 1.3020e-04, 1.8285e-01, 4.4729e-04, 1.0000e+00, 3.2093e-04,\n",
      "        1.4027e-03, 1.3210e-04, 1.0000e+00, 7.6654e-05, 1.0000e+00, 9.8606e-05,\n",
      "        1.0000e+00, 8.4164e-05, 3.0622e-02, 9.7964e-05, 1.0000e+00, 2.1553e-04,\n",
      "        1.0000e+00, 1.1705e-04, 9.5825e-01, 1.1551e-04, 1.0000e+00, 1.1612e-04,\n",
      "        9.4753e-01, 7.9382e-05, 9.9118e-01, 5.2724e-05, 1.0000e+00, 1.0084e-04,\n",
      "        1.0000e+00, 1.8218e-04, 1.0000e+00, 1.6524e-04, 9.9994e-01, 1.5643e-04,\n",
      "        9.9992e-01, 3.8266e-04, 1.0000e+00, 3.4433e-01, 1.0000e+00, 2.1215e-04,\n",
      "        9.6155e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 7.2683e-04,\n",
      "        1.0000e+00, 7.0090e-05, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.8414e-04,\n",
      "        1.0000e+00, 1.2094e-04, 1.0000e+00, 6.0928e-05, 1.0000e+00, 1.4142e-04,\n",
      "        1.0000e+00, 1.0194e-04, 1.0000e+00, 9.9165e-05], device='cuda:0',\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values: \n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 1., 1., 1., 0., 1., 0.], device='cuda:0')\n",
      "Difference: \n",
      "tensor([ 0.0000e+00, -1.3020e-04,  8.1715e-01, -4.4729e-04,  0.0000e+00,\n",
      "        -3.2093e-04,  9.9860e-01, -1.3210e-04,  0.0000e+00, -7.6654e-05,\n",
      "         0.0000e+00, -9.8606e-05,  0.0000e+00, -8.4164e-05,  9.6938e-01,\n",
      "        -9.7964e-05,  0.0000e+00, -2.1553e-04,  0.0000e+00, -1.1705e-04,\n",
      "         4.1753e-02, -1.1551e-04,  1.1921e-07, -1.1612e-04,  5.2470e-02,\n",
      "        -7.9382e-05,  8.8199e-03, -5.2724e-05,  0.0000e+00, -1.0084e-04,\n",
      "         0.0000e+00, -1.8218e-04,  0.0000e+00, -1.6524e-04,  6.4135e-05,\n",
      "        -1.5643e-04,  8.4162e-05,  9.9962e-01,  1.1921e-07, -3.4433e-01,\n",
      "         1.1921e-07, -2.1215e-04,  3.8449e-02,  0.0000e+00,  0.0000e+00,\n",
      "         4.6492e-06,  5.9605e-07, -7.2683e-04,  0.0000e+00,  9.9993e-01,\n",
      "         1.1921e-07,  0.0000e+00,  0.0000e+00,  9.9902e-01,  0.0000e+00,\n",
      "        -1.2094e-04,  0.0000e+00, -6.0928e-05,  0.0000e+00,  9.9986e-01,\n",
      "         0.0000e+00, -1.0194e-04,  0.0000e+00, -9.9165e-05], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "loss: 0.595059  [64000/1650495]\n",
      "loss: 0.811345  [128000/1650495]\n",
      "loss: 0.556853  [192000/1650495]\n",
      "loss: 0.515034  [256000/1650495]\n",
      "loss: 0.522709  [320000/1650495]\n",
      "loss: 0.501264  [384000/1650495]\n",
      "loss: 0.527256  [448000/1650495]\n",
      "loss: 0.549705  [512000/1650495]\n",
      "loss: 0.518858  [576000/1650495]\n",
      "loss: 0.520685  [640000/1650495]\n",
      "Predicted values: \n",
      "tensor([1.0000e+00, 1.2442e-05, 1.0000e+00, 1.4398e-05, 1.0000e+00, 1.6706e-05,\n",
      "        1.0000e+00, 1.7841e-05, 1.0000e+00, 1.6763e-05, 1.0000e+00, 1.5911e-05,\n",
      "        1.0000e+00, 1.4375e-05, 1.0000e+00, 1.6748e-05, 1.0000e+00, 2.5439e-05,\n",
      "        9.9044e-01, 1.6787e-05, 1.0000e+00, 2.2828e-05, 1.0000e+00, 1.4434e-05,\n",
      "        1.0000e+00, 1.4744e-05, 1.0000e+00, 1.6476e-05, 9.9997e-01, 1.6346e-05,\n",
      "        1.0000e+00, 1.8154e-05, 1.0000e+00, 2.2560e-05, 1.0000e+00, 1.7181e-05,\n",
      "        1.0000e+00, 1.6691e-05, 1.0000e+00, 3.7063e-05, 1.0000e+00, 1.3369e-05,\n",
      "        1.0000e+00, 1.5657e-05, 1.0000e+00, 1.7162e-05, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 3.9627e-05, 1.0000e+00, 2.1499e-05,\n",
      "        1.0000e+00, 1.7821e-05, 1.0000e+00, 1.9066e-05, 1.0000e+00, 1.9469e-05,\n",
      "        1.0000e+00, 2.6386e-05, 1.0000e+00, 1.4187e-05], device='cuda:0',\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values: \n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0.], device='cuda:0')\n",
      "Difference: \n",
      "tensor([ 0.0000e+00, -1.2442e-05,  0.0000e+00, -1.4398e-05,  0.0000e+00,\n",
      "        -1.6706e-05,  0.0000e+00, -1.7841e-05,  0.0000e+00, -1.6763e-05,\n",
      "         0.0000e+00, -1.5911e-05,  0.0000e+00, -1.4375e-05,  0.0000e+00,\n",
      "        -1.6748e-05,  0.0000e+00, -2.5439e-05,  9.5626e-03, -1.6787e-05,\n",
      "         0.0000e+00, -2.2828e-05,  0.0000e+00, -1.4434e-05,  0.0000e+00,\n",
      "        -1.4744e-05,  0.0000e+00, -1.6476e-05,  2.6226e-05, -1.6346e-05,\n",
      "         0.0000e+00, -1.8154e-05,  0.0000e+00, -2.2560e-05,  0.0000e+00,\n",
      "        -1.7181e-05,  0.0000e+00, -1.6691e-05,  0.0000e+00, -3.7063e-05,\n",
      "         0.0000e+00, -1.3369e-05,  1.1921e-07, -1.5657e-05,  0.0000e+00,\n",
      "        -1.7162e-05,  0.0000e+00, -1.0000e+00,  0.0000e+00, -1.0000e+00,\n",
      "         0.0000e+00, -3.9627e-05,  0.0000e+00, -2.1499e-05,  0.0000e+00,\n",
      "        -1.7821e-05,  0.0000e+00, -1.9066e-05,  0.0000e+00, -1.9469e-05,\n",
      "         0.0000e+00, -2.6386e-05,  0.0000e+00, -1.4187e-05], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.530794  [704000/1650495]\n",
      "loss: 0.506454  [768000/1650495]\n",
      "loss: 0.507176  [832000/1650495]\n",
      "loss: 0.526207  [896000/1650495]\n",
      "loss: 0.512748  [960000/1650495]\n",
      "loss: 0.532470  [1024000/1650495]\n",
      "loss: 0.513302  [1088000/1650495]\n",
      "loss: 0.512414  [1152000/1650495]\n",
      "loss: 0.540674  [1216000/1650495]\n",
      "loss: 0.502548  [1280000/1650495]\n",
      "Predicted values: \n",
      "tensor([1.0000e+00, 9.7867e-08, 1.0000e+00, 6.4314e-08, 1.0000e+00, 1.6121e-07,\n",
      "        9.9240e-01, 1.2688e-07, 1.0000e+00, 6.8108e-08, 1.0000e+00, 2.2786e-07,\n",
      "        1.0000e+00, 1.6209e-06, 1.0000e+00, 5.6692e-07, 1.0000e+00, 1.6422e-07,\n",
      "        1.0000e+00, 1.0916e-07, 1.0000e+00, 2.6069e-07, 1.0000e+00, 1.3978e-06,\n",
      "        1.0000e+00, 1.2951e-07, 1.0000e+00, 5.7398e-07, 1.0000e+00, 1.1943e-07,\n",
      "        1.0000e+00, 8.8162e-08, 7.2625e-01, 1.1575e-07, 1.0000e+00, 2.1688e-07,\n",
      "        1.0000e+00, 1.9333e-07, 1.0000e+00, 9.2004e-08, 1.0000e+00, 1.2680e-06,\n",
      "        1.0000e+00, 9.7014e-08, 1.0000e+00, 3.2372e-06, 1.0000e+00, 1.1036e-07,\n",
      "        1.0000e+00, 1.9267e-07, 9.9997e-01, 2.5726e-07, 1.0000e+00, 3.3300e-07,\n",
      "        1.0000e+00, 1.9086e-07, 1.0000e+00, 1.2560e-07, 1.0000e+00, 1.1165e-06,\n",
      "        1.0000e+00, 5.7221e-07, 1.0000e+00, 3.0030e-06], device='cuda:0',\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values: \n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0.], device='cuda:0')\n",
      "Difference: \n",
      "tensor([ 0.0000e+00, -9.7867e-08,  0.0000e+00, -6.4314e-08,  0.0000e+00,\n",
      "        -1.6121e-07,  7.6007e-03, -1.2688e-07,  0.0000e+00, -6.8108e-08,\n",
      "         0.0000e+00, -2.2786e-07,  0.0000e+00, -1.6209e-06,  0.0000e+00,\n",
      "        -5.6692e-07,  0.0000e+00, -1.6422e-07,  0.0000e+00, -1.0916e-07,\n",
      "         0.0000e+00, -2.6069e-07,  0.0000e+00, -1.3978e-06,  0.0000e+00,\n",
      "        -1.2951e-07,  0.0000e+00, -5.7398e-07,  2.3842e-07, -1.1943e-07,\n",
      "         0.0000e+00, -8.8162e-08,  2.7375e-01, -1.1575e-07,  0.0000e+00,\n",
      "        -2.1688e-07,  0.0000e+00, -1.9333e-07,  0.0000e+00, -9.2004e-08,\n",
      "         3.5763e-07, -1.2680e-06,  0.0000e+00, -9.7014e-08,  0.0000e+00,\n",
      "        -3.2372e-06,  0.0000e+00, -1.1036e-07,  0.0000e+00, -1.9267e-07,\n",
      "         3.4690e-05, -2.5726e-07,  0.0000e+00, -3.3300e-07,  0.0000e+00,\n",
      "        -1.9086e-07,  0.0000e+00, -1.2560e-07,  0.0000e+00, -1.1165e-06,\n",
      "         0.0000e+00, -5.7221e-07,  0.0000e+00, -3.0030e-06], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "loss: 0.507051  [1344000/1650495]\n",
      "loss: 0.508497  [1408000/1650495]\n",
      "loss: 0.511829  [1472000/1650495]\n",
      "loss: 0.863132  [1536000/1650495]\n",
      "loss: 0.501868  [1600000/1650495]\n",
      "Test set Error: \n",
      " Test Set Accuracy: 87.46423%, Avg Test Set loss: 0.549815 \n",
      "\n",
      "Training Set Error: \n",
      " Training Set Accuracy: 92.60779%, Avg Training Set loss: 0.531768 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.515063  [    0/1650495]\n",
      "Predicted values: \n",
      "tensor([1.0000e+00, 1.8624e-06, 1.0000e+00, 1.4018e-05, 1.0000e+00, 8.5940e-06,\n",
      "        2.5321e-04, 2.0843e-06, 1.0000e+00, 6.8068e-07, 1.0000e+00, 9.3923e-07,\n",
      "        9.9877e-01, 8.7175e-07, 1.0000e+00, 1.5624e-06, 9.9999e-01, 2.1281e-06,\n",
      "        1.0000e+00, 1.1601e-06, 1.0000e+00, 1.4751e-06, 1.0000e+00, 1.0520e-06,\n",
      "        1.0000e+00, 1.4301e-06, 9.9766e-01, 3.4479e-07, 2.7594e-02, 9.1720e-07,\n",
      "        9.9990e-01, 1.9807e-06, 1.0000e+00, 2.9972e-06, 1.0000e+00, 1.9910e-06,\n",
      "        9.4441e-08, 1.1321e-05, 1.0000e+00, 1.4401e-02, 9.9611e-01, 2.3594e-06,\n",
      "        1.0000e+00, 1.0000e+00, 3.9859e-01, 1.0000e+00, 2.2222e-06, 1.0693e-05,\n",
      "        1.0000e+00, 1.2762e-06, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9118e-05,\n",
      "        6.1893e-04, 1.2286e-06, 1.0000e+00, 7.7486e-07, 1.0000e+00, 1.9921e-06,\n",
      "        9.9997e-01, 1.2996e-06, 1.0000e+00, 1.1106e-06], device='cuda:0',\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values: \n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 1., 1., 1., 0., 1., 0.], device='cuda:0')\n",
      "Difference: \n",
      "tensor([ 0.0000e+00, -1.8624e-06,  0.0000e+00, -1.4018e-05,  0.0000e+00,\n",
      "        -8.5940e-06,  9.9975e-01, -2.0843e-06,  0.0000e+00, -6.8068e-07,\n",
      "         0.0000e+00, -9.3923e-07,  1.2289e-03, -8.7175e-07,  0.0000e+00,\n",
      "        -1.5624e-06,  6.9141e-06, -2.1281e-06,  0.0000e+00, -1.1601e-06,\n",
      "         0.0000e+00, -1.4751e-06,  0.0000e+00, -1.0520e-06,  0.0000e+00,\n",
      "        -1.4301e-06,  2.3410e-03, -3.4479e-07,  9.7241e-01, -9.1720e-07,\n",
      "         1.0192e-04, -1.9807e-06,  0.0000e+00, -2.9972e-06,  0.0000e+00,\n",
      "        -1.9910e-06,  1.0000e+00,  9.9999e-01,  4.4107e-06, -1.4401e-02,\n",
      "         3.8947e-03, -2.3594e-06,  0.0000e+00,  0.0000e+00,  6.0141e-01,\n",
      "         0.0000e+00,  1.0000e+00, -1.0693e-05,  0.0000e+00,  1.0000e+00,\n",
      "         1.9073e-06,  0.0000e+00,  0.0000e+00,  9.9990e-01,  9.9938e-01,\n",
      "        -1.2286e-06,  0.0000e+00, -7.7486e-07,  3.5763e-07,  1.0000e+00,\n",
      "         2.8253e-05, -1.2996e-06,  3.5763e-07, -1.1106e-06], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "loss: 0.580275  [64000/1650495]\n",
      "loss: 0.538855  [128000/1650495]\n",
      "loss: 0.543434  [192000/1650495]\n",
      "loss: 0.523908  [256000/1650495]\n",
      "loss: 0.510953  [320000/1650495]\n",
      "loss: 0.501266  [384000/1650495]\n",
      "loss: 0.524705  [448000/1650495]\n",
      "loss: 0.580536  [512000/1650495]\n",
      "loss: 0.507124  [576000/1650495]\n",
      "loss: 0.532173  [640000/1650495]\n",
      "Predicted values: \n",
      "tensor([1.0000e+00, 4.8982e-07, 1.0000e+00, 5.1520e-07, 9.9997e-01, 5.9000e-07,\n",
      "        1.0000e+00, 6.4597e-07, 1.0000e+00, 4.7783e-07, 1.0000e+00, 6.2807e-07,\n",
      "        1.0000e+00, 5.1211e-07, 9.9979e-01, 6.4262e-07, 1.0000e+00, 9.4302e-07,\n",
      "        1.0000e+00, 5.7762e-07, 1.0000e+00, 9.5433e-07, 1.0000e+00, 5.2233e-07,\n",
      "        1.0000e+00, 5.6895e-07, 2.4046e-02, 6.2928e-07, 1.0000e+00, 6.0142e-07,\n",
      "        1.0000e+00, 7.3177e-07, 1.0000e+00, 9.1279e-07, 1.0000e+00, 6.2565e-07,\n",
      "        1.0000e+00, 6.4431e-07, 1.0000e+00, 1.4103e-06, 1.0000e+00, 4.9692e-07,\n",
      "        2.3556e-04, 5.4576e-07, 1.0000e+00, 5.8110e-07, 1.0000e+00, 9.9879e-01,\n",
      "        1.0000e+00, 1.0000e+00, 9.9845e-01, 1.3077e-06, 1.0000e+00, 8.0709e-07,\n",
      "        1.0000e+00, 6.1879e-07, 1.0000e+00, 6.1489e-07, 1.0000e+00, 6.3884e-07,\n",
      "        1.0000e+00, 9.3441e-07, 9.9983e-01, 5.1931e-07], device='cuda:0',\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values: \n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0.], device='cuda:0')\n",
      "Difference: \n",
      "tensor([ 0.0000e+00, -4.8982e-07,  0.0000e+00, -5.1520e-07,  2.5630e-05,\n",
      "        -5.9000e-07,  0.0000e+00, -6.4597e-07,  0.0000e+00, -4.7783e-07,\n",
      "         0.0000e+00, -6.2807e-07,  0.0000e+00, -5.1211e-07,  2.0522e-04,\n",
      "        -6.4262e-07,  0.0000e+00, -9.4302e-07,  0.0000e+00, -5.7762e-07,\n",
      "         0.0000e+00, -9.5433e-07,  0.0000e+00, -5.2233e-07,  0.0000e+00,\n",
      "        -5.6895e-07,  9.7595e-01, -6.2928e-07,  0.0000e+00, -6.0142e-07,\n",
      "         0.0000e+00, -7.3177e-07,  0.0000e+00, -9.1279e-07,  0.0000e+00,\n",
      "        -6.2565e-07,  0.0000e+00, -6.4431e-07,  0.0000e+00, -1.4103e-06,\n",
      "         0.0000e+00, -4.9692e-07,  9.9976e-01, -5.4576e-07,  0.0000e+00,\n",
      "        -5.8110e-07,  1.1921e-07, -9.9879e-01,  0.0000e+00, -1.0000e+00,\n",
      "         1.5477e-03, -1.3077e-06,  0.0000e+00, -8.0709e-07,  0.0000e+00,\n",
      "        -6.1879e-07,  0.0000e+00, -6.1489e-07,  0.0000e+00, -6.3884e-07,\n",
      "         0.0000e+00, -9.3441e-07,  1.7047e-04, -5.1931e-07], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "loss: 0.518071  [704000/1650495]\n",
      "loss: 0.507560  [768000/1650495]\n",
      "loss: 0.512950  [832000/1650495]\n",
      "loss: 0.846457  [896000/1650495]\n",
      "loss: 0.510817  [960000/1650495]\n",
      "loss: 0.528760  [1024000/1650495]\n",
      "loss: 0.522609  [1088000/1650495]\n",
      "loss: 0.523950  [1152000/1650495]\n",
      "loss: 0.535796  [1216000/1650495]\n",
      "loss: 0.512947  [1280000/1650495]\n",
      "Predicted values: \n",
      "tensor([1.0000e+00, 1.0024e-08, 1.0000e+00, 7.3044e-09, 1.0000e+00, 1.4847e-08,\n",
      "        1.0000e+00, 1.4015e-08, 1.0000e+00, 7.0591e-09, 1.8980e-03, 1.4801e-08,\n",
      "        1.0000e+00, 6.6833e-08, 1.0000e+00, 3.0710e-08, 1.0000e+00, 1.0405e-08,\n",
      "        1.0000e+00, 8.9454e-09, 1.0000e+00, 1.5665e-08, 1.0000e+00, 2.5661e-08,\n",
      "        1.0000e+00, 1.0105e-08, 1.0000e+00, 2.3641e-08, 1.0000e+00, 8.5214e-09,\n",
      "        1.0000e+00, 8.3296e-09, 1.0000e+00, 1.0765e-08, 1.0000e+00, 1.7964e-08,\n",
      "        1.0000e+00, 1.5589e-08, 1.0000e+00, 9.3280e-09, 1.0000e+00, 4.4796e-08,\n",
      "        1.0000e+00, 9.2923e-09, 3.2122e-03, 1.0308e-07, 1.0000e+00, 1.0626e-08,\n",
      "        1.0000e+00, 1.4070e-08, 1.0000e+00, 1.4128e-08, 1.0000e+00, 2.0001e-08,\n",
      "        1.0000e+00, 1.5053e-08, 1.0000e+00, 8.5051e-09, 1.0000e+00, 4.3324e-08,\n",
      "        1.0000e+00, 3.2100e-08, 1.0000e+00, 8.1193e-08], device='cuda:0',\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values: \n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0.], device='cuda:0')\n",
      "Difference: \n",
      "tensor([ 0.0000e+00, -1.0024e-08,  0.0000e+00, -7.3044e-09,  0.0000e+00,\n",
      "        -1.4847e-08,  1.1921e-07, -1.4015e-08,  0.0000e+00, -7.0591e-09,\n",
      "         9.9810e-01, -1.4801e-08,  4.0531e-06, -6.6833e-08,  0.0000e+00,\n",
      "        -3.0710e-08,  0.0000e+00, -1.0405e-08,  0.0000e+00, -8.9454e-09,\n",
      "         0.0000e+00, -1.5665e-08,  0.0000e+00, -2.5661e-08,  0.0000e+00,\n",
      "        -1.0105e-08,  0.0000e+00, -2.3641e-08,  0.0000e+00, -8.5214e-09,\n",
      "         0.0000e+00, -8.3296e-09,  0.0000e+00, -1.0765e-08,  1.1921e-07,\n",
      "        -1.7964e-08,  0.0000e+00, -1.5589e-08,  0.0000e+00, -9.3280e-09,\n",
      "         0.0000e+00, -4.4796e-08,  0.0000e+00, -9.2923e-09,  9.9679e-01,\n",
      "        -1.0308e-07,  0.0000e+00, -1.0626e-08,  0.0000e+00, -1.4070e-08,\n",
      "         0.0000e+00, -1.4128e-08,  0.0000e+00, -2.0001e-08,  0.0000e+00,\n",
      "        -1.5053e-08,  0.0000e+00, -8.5051e-09,  0.0000e+00, -4.3324e-08,\n",
      "         0.0000e+00, -3.2100e-08,  0.0000e+00, -8.1193e-08], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.506578  [1344000/1650495]\n",
      "loss: 0.507124  [1408000/1650495]\n",
      "loss: 0.501763  [1472000/1650495]\n",
      "loss: 0.850761  [1536000/1650495]\n",
      "loss: 0.501268  [1600000/1650495]\n",
      "Test set Error: \n",
      " Test Set Accuracy: 87.27502%, Avg Test Set loss: 0.549091 \n",
      "\n",
      "Training Set Error: \n",
      " Training Set Accuracy: 92.78950%, Avg Training Set loss: 0.530899 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.512458  [    0/1650495]\n",
      "Predicted values: \n",
      "tensor([1.0000e+00, 6.4083e-10, 1.0000e+00, 1.3498e-08, 1.0000e+00, 3.9009e-09,\n",
      "        9.0670e-01, 8.8489e-10, 1.0000e+00, 4.3976e-10, 1.0000e+00, 4.1283e-10,\n",
      "        1.0000e+00, 3.1829e-10, 1.0000e+00, 3.7230e-10, 1.0000e+00, 1.2877e-09,\n",
      "        1.0000e+00, 8.7330e-10, 9.8483e-01, 5.6928e-10, 3.7766e-08, 3.3389e-10,\n",
      "        1.0000e+00, 6.5552e-10, 1.0000e+00, 1.5268e-10, 1.0000e+00, 3.5066e-10,\n",
      "        1.0000e+00, 1.1375e-09, 4.8348e-03, 1.2432e-09, 2.0893e-03, 7.2167e-10,\n",
      "        1.0000e+00, 3.4100e-09, 1.0000e+00, 8.6897e-07, 9.2539e-06, 1.0253e-09,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 4.1815e-09,\n",
      "        1.0000e+00, 4.8920e-10, 1.0000e+00, 1.0000e+00, 9.9997e-01, 3.4045e-08,\n",
      "        3.5683e-07, 5.2956e-10, 9.9962e-01, 3.4167e-10, 1.0000e+00, 1.1423e-09,\n",
      "        1.0000e+00, 5.2769e-10, 1.0000e+00, 3.8817e-10], device='cuda:0',\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values: \n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 1., 0., 1., 1., 1., 0., 1., 0.], device='cuda:0')\n",
      "Difference: \n",
      "tensor([ 0.0000e+00, -6.4083e-10,  0.0000e+00, -1.3498e-08,  0.0000e+00,\n",
      "        -3.9009e-09,  9.3295e-02, -8.8489e-10,  0.0000e+00, -4.3976e-10,\n",
      "         0.0000e+00, -4.1283e-10,  0.0000e+00, -3.1829e-10,  0.0000e+00,\n",
      "        -3.7230e-10,  0.0000e+00, -1.2877e-09,  0.0000e+00, -8.7330e-10,\n",
      "         1.5165e-02, -5.6928e-10,  1.0000e+00, -3.3389e-10,  0.0000e+00,\n",
      "        -6.5552e-10,  0.0000e+00, -1.5268e-10,  0.0000e+00, -3.5066e-10,\n",
      "         0.0000e+00, -1.1375e-09,  9.9517e-01, -1.2432e-09,  9.9791e-01,\n",
      "        -7.2167e-10,  0.0000e+00,  1.0000e+00,  0.0000e+00, -8.6897e-07,\n",
      "         9.9999e-01, -1.0253e-09,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -4.1815e-09,  4.0531e-06,  1.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  3.0756e-05,  1.0000e+00,  1.0000e+00,\n",
      "        -5.2956e-10,  3.7754e-04, -3.4167e-10,  0.0000e+00,  1.0000e+00,\n",
      "         0.0000e+00, -5.2769e-10,  0.0000e+00, -3.8817e-10], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "loss: 0.576464  [64000/1650495]\n",
      "loss: 0.530628  [128000/1650495]\n",
      "loss: 0.516847  [192000/1650495]\n",
      "loss: 0.539770  [256000/1650495]\n",
      "loss: 0.516813  [320000/1650495]\n",
      "loss: 0.501262  [384000/1650495]\n",
      "loss: 0.504578  [448000/1650495]\n",
      "loss: 0.549833  [512000/1650495]\n",
      "loss: 0.518955  [576000/1650495]\n",
      "loss: 0.520860  [640000/1650495]\n",
      "Predicted values: \n",
      "tensor([1.0000e+00, 3.2126e-08, 1.0000e+00, 3.6457e-08, 1.0000e+00, 4.4508e-08,\n",
      "        1.0000e+00, 4.7492e-08, 1.0000e+00, 3.7642e-08, 1.0000e+00, 5.7243e-08,\n",
      "        1.0000e+00, 3.7345e-08, 1.0000e+00, 4.2652e-08, 1.0000e+00, 8.2576e-08,\n",
      "        1.0000e+00, 4.0034e-08, 1.0000e+00, 7.2667e-08, 1.0000e+00, 3.6417e-08,\n",
      "        1.0000e+00, 3.9041e-08, 9.9995e-01, 4.1457e-08, 1.0000e+00, 4.4238e-08,\n",
      "        9.4826e-01, 4.8850e-08, 1.0000e+00, 6.0749e-08, 9.9995e-01, 4.5537e-08,\n",
      "        1.0000e+00, 4.7070e-08, 1.0000e+00, 1.3978e-07, 1.0000e+00, 3.1764e-08,\n",
      "        1.0000e+00, 3.4157e-08, 1.0000e+00, 4.1865e-08, 1.0000e+00, 1.0000e+00,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.5625e-07, 1.0000e+00, 7.4911e-08,\n",
      "        1.0000e+00, 3.8888e-08, 1.0000e+00, 4.1893e-08, 1.0000e+00, 4.6222e-08,\n",
      "        1.0000e+00, 8.0606e-08, 1.0000e+00, 3.7612e-08], device='cuda:0',\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values: \n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0.], device='cuda:0')\n",
      "Difference: \n",
      "tensor([ 0.0000e+00, -3.2126e-08,  0.0000e+00, -3.6457e-08,  0.0000e+00,\n",
      "        -4.4508e-08,  0.0000e+00, -4.7492e-08,  0.0000e+00, -3.7642e-08,\n",
      "         0.0000e+00, -5.7243e-08,  7.1526e-07, -3.7345e-08,  0.0000e+00,\n",
      "        -4.2652e-08,  0.0000e+00, -8.2576e-08,  0.0000e+00, -4.0034e-08,\n",
      "         0.0000e+00, -7.2667e-08,  0.0000e+00, -3.6417e-08,  0.0000e+00,\n",
      "        -3.9041e-08,  4.9472e-05, -4.1457e-08,  0.0000e+00, -4.4238e-08,\n",
      "         5.1739e-02, -4.8850e-08,  0.0000e+00, -6.0749e-08,  5.0545e-05,\n",
      "        -4.5537e-08,  0.0000e+00, -4.7070e-08,  0.0000e+00, -1.3978e-07,\n",
      "         0.0000e+00, -3.1764e-08,  0.0000e+00, -3.4157e-08,  0.0000e+00,\n",
      "        -4.1865e-08,  0.0000e+00, -1.0000e+00,  0.0000e+00, -1.0000e+00,\n",
      "         0.0000e+00, -1.5625e-07,  0.0000e+00, -7.4911e-08,  0.0000e+00,\n",
      "        -3.8888e-08,  0.0000e+00, -4.1893e-08,  0.0000e+00, -4.6222e-08,\n",
      "         0.0000e+00, -8.0606e-08,  0.0000e+00, -3.7612e-08], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "loss: 0.510961  [704000/1650495]\n",
      "loss: 0.501263  [768000/1650495]\n",
      "loss: 0.502162  [832000/1650495]\n",
      "loss: 0.530749  [896000/1650495]\n",
      "loss: 0.519131  [960000/1650495]\n",
      "loss: 0.508088  [1024000/1650495]\n",
      "loss: 0.515609  [1088000/1650495]\n",
      "loss: 0.501263  [1152000/1650495]\n",
      "loss: 0.536149  [1216000/1650495]\n",
      "loss: 0.512987  [1280000/1650495]\n",
      "Predicted values: \n",
      "tensor([1.0000e+00, 2.8535e-09, 1.0000e+00, 2.4344e-09, 1.0000e+00, 5.7310e-09,\n",
      "        1.0000e+00, 4.4157e-09, 1.0000e+00, 2.4541e-09, 1.0000e+00, 6.9032e-09,\n",
      "        1.0000e+00, 3.6372e-08, 9.9967e-01, 1.4094e-08, 1.0000e+00, 4.7189e-09,\n",
      "        1.0000e+00, 3.4621e-09, 1.0000e+00, 6.9112e-09, 1.0000e+00, 1.8625e-08,\n",
      "        1.0000e+00, 3.9449e-09, 1.0000e+00, 1.1552e-08, 1.0000e+00, 3.3226e-09,\n",
      "        1.0000e+00, 4.5337e-09, 1.0000e+00, 4.3042e-09, 1.0000e+00, 7.0792e-09,\n",
      "        1.0000e+00, 6.1379e-09, 1.0000e+00, 3.0943e-09, 1.0000e+00, 4.1945e-08,\n",
      "        1.0000e+00, 3.6546e-09, 1.0000e+00, 4.7105e-08, 3.0092e-08, 4.3166e-09,\n",
      "        1.0000e+00, 5.3952e-09, 1.0000e+00, 8.2849e-09, 1.0000e+00, 8.0913e-09,\n",
      "        1.0000e+00, 6.2427e-09, 1.0000e+00, 4.4803e-09, 1.5368e-07, 2.6572e-08,\n",
      "        1.0000e+00, 1.4199e-08, 1.0000e+00, 3.5989e-08], device='cuda:0',\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "Actual values: \n",
      "tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 1., 0.], device='cuda:0')\n",
      "Difference: \n",
      "tensor([ 0.0000e+00, -2.8535e-09,  0.0000e+00, -2.4344e-09,  0.0000e+00,\n",
      "        -5.7310e-09,  0.0000e+00, -4.4157e-09,  0.0000e+00, -2.4541e-09,\n",
      "         0.0000e+00, -6.9032e-09,  0.0000e+00, -3.6372e-08,  3.3414e-04,\n",
      "        -1.4094e-08,  0.0000e+00, -4.7189e-09,  0.0000e+00, -3.4621e-09,\n",
      "         0.0000e+00, -6.9112e-09,  0.0000e+00, -1.8625e-08,  0.0000e+00,\n",
      "        -3.9449e-09,  0.0000e+00, -1.1552e-08,  0.0000e+00, -3.3226e-09,\n",
      "         0.0000e+00, -4.5337e-09,  0.0000e+00, -4.3042e-09,  0.0000e+00,\n",
      "        -7.0792e-09,  0.0000e+00, -6.1379e-09,  0.0000e+00, -3.0943e-09,\n",
      "         0.0000e+00, -4.1945e-08,  0.0000e+00, -3.6546e-09,  0.0000e+00,\n",
      "        -4.7105e-08,  1.0000e+00, -4.3166e-09,  0.0000e+00, -5.3952e-09,\n",
      "         0.0000e+00, -8.2849e-09,  0.0000e+00, -8.0913e-09,  0.0000e+00,\n",
      "        -6.2427e-09,  0.0000e+00, -4.4803e-09,  1.0000e+00, -2.6572e-08,\n",
      "         0.0000e+00, -1.4199e-08,  0.0000e+00, -3.5989e-08], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "loss: 0.508435  [1344000/1650495]\n",
      "loss: 0.512986  [1408000/1650495]\n",
      "loss: 0.501448  [1472000/1650495]\n",
      "loss: 0.828721  [1536000/1650495]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    \n",
    "    train_loop(train_dataloader, model, loss, optimizer)    \n",
    "    test_loop(test_dataloader, model, loss)\n",
    "    test_loop(train_dataloader, model, loss, test_set = False)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model, and inspect the errors\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "\n",
    "print(f\"../trained_models/model_{now.strftime('%m_%d_%Y_%H_%M_%S')}\")\n",
    "\n",
    "model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "model_scripted.save(f\"../trained_models/model_{now.strftime('%m_%d_%Y_%H_%M_%S')}\") # Save\n",
    "\n",
    "print('debug')\n",
    "#randChannel = \n",
    "#testData = ds2\n",
    "#self.labels[channel, start : start + self.sectionLength]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = torch.load(\"../trained_models/model_03_21_2022_23_19_06\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.stop() # Stop the neptune logging run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda-2020.11/bin/python3\n",
      "/bin/bash: ^s: command not found\n"
     ]
    }
   ],
   "source": [
    "!which python3"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d334debdbe0c15d06a22e1a5d8333410545070b029a2d558077d9bd2658c7aed"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "neptune": {
   "notebookId": "95f2132b-e8b8-43da-ae1c-99722613d84e",
   "projectVersion": 2
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
